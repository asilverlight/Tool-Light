<h1 align="center"> ðŸ’¡Toward Effective Tool-Integrated Reasoning via
Self-Evolved Preference Learning</a></h1>


<div align="center"> 

[![License](https://img.shields.io/badge/LICENSE-MIT-green.svg)](https://opensource.org/licenses/MIT) 
[![Python 3.9+](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/downloads/release/python-390/) 
</div>

## ðŸ˜ƒ Overview


**Tool-Light** is a framework focused on enabling models to efficiently complete TIR tasks. Tool-Light innovatively introduces the **Entropy-Guided Sampling Strategy** to construct the training set. Besides, it trains the model through the **Self-Evolved DPO Pipeline**. This design empowers the model to gradually acquire the ability to call tools efficiently and accurately. Results on two types of reasoning tasks demonstrate superior performance compared to traditional methods.

<p align="center">
<img width="100%" alt="image" src="figs/tree_sampling.pdf" />
</p>